# run Open-WebUI
#docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
# run Ollama
#docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    ports:
      - "3000:8080"
    volumes:
      - "open-webui:/app/backend/data"
    environment:
      - gpus=all
      - OPENWEATHER_API_KEY=bab87f014e91b33605cf8c69dc3db86d
      - ENV=dev
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]    
    networks:
      - deepseek
    hostname: open-webui
    restart: unless-stopped
    profiles:
      - ${ENABLE_OPENWEBUI:-enabled}   

  ollama:
    image: ollama/ollama:latest
    volumes:
      - "ollama:/root/.ollama"
    ports:
      - "11434:11434"
    environment:
      - gpus=all
    networks:
      - deepseek
    hostname: ollama
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - ${ENABLE_OLLAMA:-enabled}    

  postgres:
    image: pgvector/pgvector:pg16
    environment:
      - POSTGRES_DB=vectordb
      - POSTGRES_USER=raguser
      - POSTGRES_PASSWORD=ragpassword
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      #- ./setup_vectordb.sql:/docker-entrypoint-initdb.d/setup_vectordb.sql
    networks:
      - deepseek
    hostname: postgres
    restart: unless-stopped
    profiles:
      - ${ENABLE_POSTGRES:-disabled}

  docling:
    image: ghcr.io/docling-project/docling-serve-cu128
    ports:
      - "5001:5001"
    environment:
      - DOCLING_SERVE_ENABLE_UI=true
      - DOCLING_SERVE_MAX_SYNC_WAIT=3600
      - DOCLING_SERVE_PORT=5001            
      - DOCLING_SERVE_STORAGE_PATH=/app/documents
      - DOCLING_SERVE_LOG_LEVEL=info
      - NVIDIA_VISIBLE_DEVICES="1"
      - CUDA_LAUNCH_BLOCKING=1
    runtime: "nvidia"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]   
    volumes:
      - ./documents:/app/documents
    networks:
      - deepseek
    hostname: docling
    restart: unless-stopped
    profiles:
      - ${ENABLE_DOCLING:-disabled}

  vllm:
    image: vllm/vllm-openai:latest
    ports:
      - "8000:8000"
    volumes:
      - "vllm_cache:/root/.cache/huggingface"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    command: --model Qwen/Qwen3-4B-Instruct-2507-FP8 --host 0.0.0.0 --port 8000 --max-model-len 8192 --gpu-memory-utilization 0.8
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - deepseek
    hostname: vllm
    restart: unless-stopped
    profiles:
      - ${ENABLE_VLLM:-disabled}

  development:
    build:
      context: .
      dockerfile: Dockerfile.dev   # Ensure you have a Dockerfile.dev at the root of your project.
    volumes:
      - .:/workspace   # Mounts your working directory inside the container.
      - /mnt/c/Users/flyluk/Downloads:/workfiles
      - /home/fly/development:/development

    ports:
      - "8000:8000"   # Adjust or add additional ports as needed.
    environment:
      - ENV=development
      - DATABASE_URL=postgresql://raguser:ragpassword@postgres:5432/vectordb
      - DOCLING_URL=http://docling:5001
      - OPENWEBUI_URL=http://open-webui:8080
      - OLLAMA_API_URL=http://ollama:11434
           
    networks:
      - deepseek
    hostname: development
    restart: unless-stopped
    depends_on:
      - postgres
      - docling
    profiles:
      - ${ENABLE_DEVELOPMENT:-disabled}
networks:
  deepseek:
    driver: bridge

volumes:
  open-webui:
    external: true
  ollama:
    external: true
  postgres_data:
    external: true
  vllm_cache:
    external: true
